"""
Servi√ßo de RAG (Retrieval-Augmented Generation) para SmartRx AI
Busca sem√¢ntica no banco de conhecimento e gera√ß√£o de prescri√ß√µes
"""

import os
import logging
from typing import List, Dict, Optional
from decouple import config
from openai import OpenAI
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from pgvector.sqlalchemy import Vector

logger = logging.getLogger(__name__)

class RAGService:
    """Servi√ßo para busca RAG e gera√ß√£o de prescri√ß√µes"""
    
    def __init__(self):
        # Tenta carregar a chave
        api_key = config('OPENAI_API_KEY', default=None)
        
        # --- O TIRA-TEIMA (PRINT DA VERDADE) ---
        print("\n" + "="*50)
        if api_key:
            # Mostra os primeiros caracteres para conferirmos
            print(f"üîç O BACKEND CARREGOU ESTA CHAVE: {api_key[:8]}... (oculto)")
        else:
            print("‚ùå NENHUMA CHAVE ENCONTRADA!")
        print("="*50 + "\n")
        # ---------------------------------------

        # Inicializa o cliente OpenAI com a chave carregada
        self.openai_client = OpenAI(api_key=api_key)
        
        self.embedding_model = "text-embedding-3-small"
        self.llm_model = "gpt-4o"
        self.db_url = self._get_db_url()
        self.engine = create_engine(self.db_url, echo=False)
        self.Session = sessionmaker(bind=self.engine)
    
    def _get_db_url(self) -> str:
        """Obt√©m URL de conex√£o do banco de dados"""
        database_url = os.getenv('DATABASE_URL')
        
        if database_url:
            if database_url.startswith('postgres://'):
                database_url = database_url.replace('postgres://', 'postgresql://', 1)
            return database_url
        
        # Fallback: constr√≥i URL a partir de vari√°veis individuais
        host = config('POSTGRES_HOST', default='localhost')
        port = config('POSTGRES_PORT', default=5432, cast=int)
        database = config('POSTGRES_DB', default='prescrittomed_db')
        user = config('POSTGRES_USER', default='prescrittomed')
        password = config('POSTGRES_PASSWORD', default='prescrittomed_pass')
        
        return f"postgresql://{user}:{password}@{host}:{port}/{database}"
    
    def generate_embedding(self, text: str) -> List[float]:
        """Gera embedding vetorial para um texto usando OpenAI"""
        try:
            response = self.openai_client.embeddings.create(
                model=self.embedding_model,
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Erro ao gerar embedding: {e}")
            raise
    
    def search_knowledge_base(
        self, 
        query_embedding: List[float], 
        limit: int = 5,
        min_similarity: float = 0.7
    ) -> List[Dict]:
        """Busca no banco de conhecimento usando similaridade de cosseno"""
        session = self.Session()
        try:
            # Converte lista para formato aceito pelo pgvector
            embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'
            
            from sqlalchemy import bindparam
            
            query = text("""
                SELECT 
                    id,
                    content,
                    source_type,
                    source_title,
                    source_id,
                    version_date,
                    metadata,
                    1 - (embedding <=> CAST(:embedding_vec AS vector)) AS similarity
                FROM knowledge_base
                WHERE 
                    validity_status = 'ACTIVE'
                    AND embedding IS NOT NULL
                    AND (1 - (embedding <=> CAST(:embedding_vec AS vector))) >= :min_sim
                ORDER BY embedding <=> CAST(:embedding_vec AS vector)
                LIMIT :limit
            """).bindparams(
                bindparam('embedding_vec', embedding_str),
                bindparam('min_sim', min_similarity),
                bindparam('limit', limit)
            )
            
            result = session.execute(query)
            
            results = []
            for row in result:
                results.append({
                    'id': str(row.id),
                    'content': row.content,
                    'source_type': row.source_type,
                    'source_title': row.source_title,
                    'source_id': row.source_id or '',
                    'version_date': row.version_date.isoformat() if row.version_date else None,
                    'metadata': row.metadata or {},
                    'similarity': float(row.similarity)
                })
            
            return results
            
        except Exception as e:
            logger.error(f"Erro ao buscar no knowledge base: {e}")
            raise
        finally:
            session.close()
    
    def generate_prescription(
        self, 
        symptoms: str, 
        diagnosis: Optional[str],
        context_docs: List[Dict]
    ) -> Dict:
        """Gera prescri√ß√£o usando GPT-4o com contexto RAG"""
        
        # Constr√≥i contexto a partir dos documentos encontrados
        context_text = "\n\n".join([
            f"[Fonte: {doc['source_title']} ({doc['source_type']})]\n{doc['content']}"
            for doc in context_docs
        ])
        
        system_prompt = """Voc√™ √© um assistente m√©dico especializado em gerar prescri√ß√µes baseadas em protocolos cl√≠nicos oficiais.

IMPORTANTE:
- Voc√™ √© uma ferramenta de APOIO √† decis√£o. O m√©dico √© sempre o respons√°vel final.
- Baseie-se APENAS nas fontes fornecidas no contexto.
- Se n√£o houver informa√ß√£o suficiente no contexto, indique isso claramente.
- Sempre cite as fontes usadas.
- Siga a estrutura JSON fornecida.

Retorne APENAS JSON v√°lido, sem markdown ou texto adicional."""

        user_prompt = f"""Com base nos sintomas e diagn√≥stico abaixo, e usando APENAS as informa√ß√µes do contexto fornecido, gere uma prescri√ß√£o m√©dica estruturada.

SINTOMAS: {symptoms}
DIAGN√ìSTICO: {diagnosis or 'N√£o especificado'}

CONTEXTO (Fontes Consultadas):
{context_text}

Retorne um JSON com a seguinte estrutura:
{{
    "medicamentos": [
        {{
            "nome": "Nome comercial",
            "principio_ativo": "Princ√≠pio ativo",
            "forma": "Forma farmac√™utica",
            "concentracao": "Concentra√ß√£o",
            "posologia": "Posologia detalhada",
            "via": "Via de administra√ß√£o",
            "frequencia": "Frequ√™ncia",
            "duracao": "Dura√ß√£o",
            "observacoes": "Observa√ß√µes (opcional)"
        }}
    ],
    "resumo_tecnico_medico": ["ponto 1", "ponto 2"],
    "orientacoes_ao_paciente": ["orienta√ß√£o 1", "orienta√ß√£o 2"],
    "alertas_seguranca": ["alerta 1", "alerta 2"],
    "monitorizacao": ["item 1", "item 2"]
}}"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.0,
                response_format={"type": "json_object"}
            )
            
            import json
            prescription_json = json.loads(response.choices[0].message.content)
            
            # Adiciona informa√ß√µes das fontes
            prescription_json['fontes'] = [
                {
                    'source_id': doc['source_id'],
                    'source_type': doc['source_type'],
                    'title': doc['source_title'],
                    'confidence_score': doc['similarity']
                }
                for doc in context_docs
            ]
            
            if context_docs:
                prescription_json['confidence_score'] = sum(
                    doc['similarity'] for doc in context_docs
                ) / len(context_docs)
            else:
                prescription_json['confidence_score'] = 0.0
            
            return prescription_json
            
        except Exception as e:
            logger.error(f"Erro ao gerar prescri√ß√£o: {e}")
            raise
    
    def prescribe(
        self, 
        symptoms: str, 
        diagnosis: Optional[str] = None
    ) -> Dict:
        """M√©todo principal: busca RAG + gera√ß√£o de prescri√ß√£o"""
        
        # 1. Gera embedding da query
        query_text = f"{symptoms} {diagnosis or ''}".strip()
        query_embedding = self.generate_embedding(query_text)
        
        # 2. Busca no knowledge base
        context_docs = self.search_knowledge_base(query_embedding, limit=5, min_similarity=0.7)
        
        # 3. Se n√£o encontrou documentos suficientes, retorna erro
        if not context_docs:
            raise ValueError(
                "N√£o foram encontrados protocolos cl√≠nicos suficientes para gerar a prescri√ß√£o. "
                "Sistema em modo manual."
            )
        
        # 4. Gera prescri√ß√£o com contexto
        prescription = self.generate_prescription(symptoms, diagnosis, context_docs)
        
        return prescription